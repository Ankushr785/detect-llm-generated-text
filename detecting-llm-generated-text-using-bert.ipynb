{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7105bd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:18.600557Z",
     "iopub.status.busy": "2024-01-13T08:24:18.600191Z",
     "iopub.status.idle": "2024-01-13T08:24:19.309251Z",
     "shell.execute_reply": "2024-01-13T08:24:19.308324Z"
    },
    "papermill": {
     "duration": 0.718909,
     "end_time": "2024-01-13T08:24:19.311451",
     "exception": false,
     "start_time": "2024-01-13T08:24:18.592542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n",
      "/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n",
      "/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n",
      "/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n",
      "/kaggle/input/bert-initialization/kaggle/working/bert_base_uncased_pretrained_model_pytorch_primary/config.json\n",
      "/kaggle/input/bert-initialization/kaggle/working/bert_base_uncased_pretrained_model_pytorch_primary/tokenizer.json\n",
      "/kaggle/input/bert-initialization/kaggle/working/bert_base_uncased_pretrained_model_pytorch_primary/tokenizer_config.json\n",
      "/kaggle/input/bert-initialization/kaggle/working/bert_base_uncased_pretrained_model_pytorch_primary/model.safetensors\n",
      "/kaggle/input/bert-initialization/kaggle/working/bert_base_uncased_pretrained_model_pytorch_primary/special_tokens_map.json\n",
      "/kaggle/input/bert-initialization/kaggle/working/bert_base_uncased_pretrained_model_pytorch_primary/vocab.txt\n",
      "/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model/config.json\n",
      "/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model/tokenizer.json\n",
      "/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model/tokenizer_config.json\n",
      "/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model/model.safetensors\n",
      "/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model/special_tokens_map.json\n",
      "/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54975ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:19.324094Z",
     "iopub.status.busy": "2024-01-13T08:24:19.323476Z",
     "iopub.status.idle": "2024-01-13T08:24:19.327545Z",
     "shell.execute_reply": "2024-01-13T08:24:19.326707Z"
    },
    "papermill": {
     "duration": 0.012496,
     "end_time": "2024-01-13T08:24:19.329541",
     "exception": false,
     "start_time": "2024-01-13T08:24:19.317045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d5ae52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:19.341293Z",
     "iopub.status.busy": "2024-01-13T08:24:19.340994Z",
     "iopub.status.idle": "2024-01-13T08:24:25.410184Z",
     "shell.execute_reply": "2024-01-13T08:24:25.409381Z"
    },
    "papermill": {
     "duration": 6.077589,
     "end_time": "2024-01-13T08:24:25.412532",
     "exception": false,
     "start_time": "2024-01-13T08:24:19.334943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc4411d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:25.424935Z",
     "iopub.status.busy": "2024-01-13T08:24:25.424474Z",
     "iopub.status.idle": "2024-01-13T08:24:25.526170Z",
     "shell.execute_reply": "2024-01-13T08:24:25.525277Z"
    },
    "papermill": {
     "duration": 0.110468,
     "end_time": "2024-01-13T08:24:25.528574",
     "exception": false,
     "start_time": "2024-01-13T08:24:25.418106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')\n",
    "train_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d356070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:25.541506Z",
     "iopub.status.busy": "2024-01-13T08:24:25.540885Z",
     "iopub.status.idle": "2024-01-13T08:24:25.544929Z",
     "shell.execute_reply": "2024-01-13T08:24:25.543883Z"
    },
    "papermill": {
     "duration": 0.012618,
     "end_time": "2024-01-13T08:24:25.546925",
     "exception": false,
     "start_time": "2024-01-13T08:24:25.534307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c42230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:25.559116Z",
     "iopub.status.busy": "2024-01-13T08:24:25.558522Z",
     "iopub.status.idle": "2024-01-13T08:24:25.562468Z",
     "shell.execute_reply": "2024-01-13T08:24:25.561636Z"
    },
    "papermill": {
     "duration": 0.01207,
     "end_time": "2024-01-13T08:24:25.564362",
     "exception": false,
     "start_time": "2024-01-13T08:24:25.552292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_path = '/kaggle/working/distilbert_base_uncased_finetuned_model'\n",
    "\n",
    "# !mkdir {save_path}\n",
    "\n",
    "# model.save_pretrained(save_path)\n",
    "# tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# !ls {save_path}\n",
    "# !zip -r distilbert_uncased.zip {save_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a69451d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:25.576188Z",
     "iopub.status.busy": "2024-01-13T08:24:25.575934Z",
     "iopub.status.idle": "2024-01-13T08:24:25.579788Z",
     "shell.execute_reply": "2024-01-13T08:24:25.578862Z"
    },
    "papermill": {
     "duration": 0.011938,
     "end_time": "2024-01-13T08:24:25.581639",
     "exception": false,
     "start_time": "2024-01-13T08:24:25.569701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_path = \"/kaggle/input/distilbert-initialization/kaggle/working/distilbert_base_uncased_finetuned_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae26134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:25.593810Z",
     "iopub.status.busy": "2024-01-13T08:24:25.593511Z",
     "iopub.status.idle": "2024-01-13T08:24:27.772593Z",
     "shell.execute_reply": "2024-01-13T08:24:27.771724Z"
    },
    "papermill": {
     "duration": 2.187973,
     "end_time": "2024-01-13T08:24:27.775158",
     "exception": false,
     "start_time": "2024-01-13T08:24:25.587185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(load_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(load_path, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b541781f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:27.788004Z",
     "iopub.status.busy": "2024-01-13T08:24:27.787530Z",
     "iopub.status.idle": "2024-01-13T08:24:28.052554Z",
     "shell.execute_reply": "2024-01-13T08:24:28.051573Z"
    },
    "papermill": {
     "duration": 0.273744,
     "end_time": "2024-01-13T08:24:28.054601",
     "exception": false,
     "start_time": "2024-01-13T08:24:27.780857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36d1679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:28.067558Z",
     "iopub.status.busy": "2024-01-13T08:24:28.066981Z",
     "iopub.status.idle": "2024-01-13T08:24:29.872085Z",
     "shell.execute_reply": "2024-01-13T08:24:29.871019Z"
    },
    "papermill": {
     "duration": 1.814218,
     "end_time": "2024-01-13T08:24:29.874581",
     "exception": false,
     "start_time": "2024-01-13T08:24:28.060363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(list(train_essays['text']), padding=True, truncation=True, \n",
    "                             return_tensors=\"pt\")\n",
    "labels = torch.tensor(train_essays['generated'])\n",
    "\n",
    "dataset = TensorDataset(tokenized_inputs[\"input_ids\"], \n",
    "                        tokenized_inputs[\"attention_mask\"], labels)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18742de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:24:29.887703Z",
     "iopub.status.busy": "2024-01-13T08:24:29.887357Z",
     "iopub.status.idle": "2024-01-13T08:55:15.271656Z",
     "shell.execute_reply": "2024-01-13T08:55:15.270754Z"
    },
    "papermill": {
     "duration": 1845.393201,
     "end_time": "2024-01-13T08:55:15.273929",
     "exception": false,
     "start_time": "2024-01-13T08:24:29.880728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]\n",
      "525it [00:33, 20.85it/s]\n",
      "1050it [01:09, 19.94it/s]\n",
      "1575it [01:46, 19.86it/s]\n",
      "2100it [02:23, 19.85it/s]\n",
      "2625it [03:00, 19.86it/s]\n",
      "3150it [03:37, 19.85it/s]\n",
      "3675it [04:14, 19.86it/s]\n",
      "4200it [04:51, 19.86it/s]\n",
      "4725it [05:28, 19.85it/s]\n",
      "5250it [06:05, 19.86it/s]\n",
      "5775it [06:41, 19.86it/s]\n",
      "6300it [07:18, 19.86it/s]\n",
      "6825it [07:55, 19.86it/s]\n",
      "7350it [08:32, 19.86it/s]\n",
      "7875it [09:09, 19.86it/s]\n",
      "8400it [09:46, 19.85it/s]\n",
      "8925it [10:23, 19.86it/s]\n",
      "9450it [11:00, 19.86it/s]\n",
      "9975it [11:36, 19.86it/s]\n",
      "10500it [12:13, 19.86it/s]\n",
      "11025it [12:50, 19.85it/s]\n",
      "11550it [13:27, 19.85it/s]\n",
      "12075it [14:04, 19.85it/s]\n",
      "12600it [14:41, 19.85it/s]\n",
      "13125it [15:18, 19.85it/s]\n",
      "13650it [15:55, 19.85it/s]\n",
      "14175it [16:31, 19.85it/s]\n",
      "14700it [17:08, 19.86it/s]\n",
      "15225it [17:45, 19.86it/s]\n",
      "15750it [18:22, 19.85it/s]\n",
      "16275it [18:59, 19.85it/s]\n",
      "16800it [19:36, 19.86it/s]\n",
      "17325it [20:13, 19.86it/s]\n",
      "17850it [20:50, 19.86it/s]\n",
      "18375it [21:27, 19.85it/s]\n",
      "18900it [22:03, 19.86it/s]\n",
      "19425it [22:40, 19.85it/s]\n",
      "19950it [23:17, 19.86it/s]\n",
      "20475it [23:54, 19.85it/s]\n",
      "21000it [24:31, 19.85it/s]\n",
      "21525it [25:08, 19.86it/s]\n",
      "22050it [25:45, 19.86it/s]\n",
      "22575it [26:22, 19.86it/s]\n",
      "23100it [26:59, 19.86it/s]\n",
      "23625it [27:35, 19.86it/s]\n",
      "24150it [28:12, 19.85it/s]\n",
      "24675it [28:49, 19.86it/s]\n",
      "25200it [29:26, 19.86it/s]\n",
      "25725it [30:03, 19.86it/s]\n",
      "26250it [30:40, 19.86it/s]\n",
      "100%|██████████| 50/50 [30:44<00:00, 36.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fine_tuned_model/tokenizer_config.json',\n",
       " 'fine_tuned_model/special_tokens_map.json',\n",
       " 'fine_tuned_model/vocab.txt',\n",
       " 'fine_tuned_model/added_tokens.json',\n",
       " 'fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "pbar1 = tqdm(total = len(dataloader))\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i,batch in enumerate(dataloader):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        input_ids, attention_mask, label = input_ids.to(\"cuda\"), attention_mask.to(\"cuda\"), label.to(\"cuda\") \n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%25==0:\n",
    "            pbar1.update(i)\n",
    "\n",
    "model.save_pretrained(\"fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5288763c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:15.357028Z",
     "iopub.status.busy": "2024-01-13T08:55:15.356714Z",
     "iopub.status.idle": "2024-01-13T08:55:15.367526Z",
     "shell.execute_reply": "2024-01-13T08:55:15.366795Z"
    },
    "papermill": {
     "duration": 0.054343,
     "end_time": "2024-01-13T08:55:15.369453",
     "exception": false,
     "start_time": "2024-01-13T08:55:15.315110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a83a80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:15.452479Z",
     "iopub.status.busy": "2024-01-13T08:55:15.452139Z",
     "iopub.status.idle": "2024-01-13T08:55:30.154428Z",
     "shell.execute_reply": "2024-01-13T08:55:30.153634Z"
    },
    "papermill": {
     "duration": 14.745604,
     "end_time": "2024-01-13T08:55:30.156554",
     "exception": false,
     "start_time": "2024-01-13T08:55:15.410950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26250it [31:00, 19.86it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for text in train_essays.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions.append(torch.nn.functional.sigmoid(outputs.logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b134d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:30.239943Z",
     "iopub.status.busy": "2024-01-13T08:55:30.239598Z",
     "iopub.status.idle": "2024-01-13T08:55:30.281538Z",
     "shell.execute_reply": "2024-01-13T08:55:30.280770Z"
    },
    "papermill": {
     "duration": 0.08572,
     "end_time": "2024-01-13T08:55:30.283476",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.197756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = [np.array(a.to(\"cpu\"))[0][1] for a in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f81b07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:30.366383Z",
     "iopub.status.busy": "2024-01-13T08:55:30.366049Z",
     "iopub.status.idle": "2024-01-13T08:55:30.379300Z",
     "shell.execute_reply": "2024-01-13T08:55:30.378175Z"
    },
    "papermill": {
     "duration": 0.056769,
     "end_time": "2024-01-13T08:55:30.381251",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.324482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score train =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC-AUC score train = \", roc_auc_score(train_essays['generated'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f9f3c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:30.466159Z",
     "iopub.status.busy": "2024-01-13T08:55:30.465276Z",
     "iopub.status.idle": "2024-01-13T08:55:30.488942Z",
     "shell.execute_reply": "2024-01-13T08:55:30.488050Z"
    },
    "papermill": {
     "duration": 0.067536,
     "end_time": "2024-01-13T08:55:30.490954",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.423418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_test = []\n",
    "with torch.no_grad():\n",
    "    for text in test_essays.text:\n",
    "        \n",
    "        input_ids = tokenizer(text, \n",
    "                      padding=True, \n",
    "                      truncation=True,  \n",
    "                      return_tensors='pt')[\"input_ids\"].to(\"cuda\")\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        predictions_test.append(torch.nn.functional.sigmoid(outputs.logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8402ab35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:30.573996Z",
     "iopub.status.busy": "2024-01-13T08:55:30.573696Z",
     "iopub.status.idle": "2024-01-13T08:55:30.578674Z",
     "shell.execute_reply": "2024-01-13T08:55:30.577825Z"
    },
    "papermill": {
     "duration": 0.048875,
     "end_time": "2024-01-13T08:55:30.580512",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.531637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_test = [np.array(a.to(\"cpu\"))[0][1] for a in predictions_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42044d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:30.664142Z",
     "iopub.status.busy": "2024-01-13T08:55:30.663846Z",
     "iopub.status.idle": "2024-01-13T08:55:30.668690Z",
     "shell.execute_reply": "2024-01-13T08:55:30.667841Z"
    },
    "papermill": {
     "duration": 0.049405,
     "end_time": "2024-01-13T08:55:30.670597",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.621192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_essays['generated'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67ea5247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T08:55:30.753722Z",
     "iopub.status.busy": "2024-01-13T08:55:30.753175Z",
     "iopub.status.idle": "2024-01-13T08:55:30.764546Z",
     "shell.execute_reply": "2024-01-13T08:55:30.763699Z"
    },
    "papermill": {
     "duration": 0.055115,
     "end_time": "2024-01-13T08:55:30.766480",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.711365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_essays[['id', 'generated']].to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24e6be",
   "metadata": {
    "papermill": {
     "duration": 0.04055,
     "end_time": "2024-01-13T08:55:30.847821",
     "exception": false,
     "start_time": "2024-01-13T08:55:30.807271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 4296796,
     "sourceId": 7391332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4298382,
     "sourceId": 7393672,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1878.256908,
   "end_time": "2024-01-13T08:55:33.424437",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-13T08:24:15.167529",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
